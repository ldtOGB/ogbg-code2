{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ogbg-code2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 2.0.1+cu118\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "# The PyG built-in GCNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from ogb.graphproppred import Evaluator\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cuda',\n",
       " 'num_layers': 5,\n",
       " 'hidden_dim': 256,\n",
       " 'dropout': 0.5,\n",
       " 'lr': 0.001,\n",
       " 'epochs': 30}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {\n",
    "      'device': device,\n",
    "      'num_layers': 5,\n",
    "      'hidden_dim': 256,\n",
    "      'dropout': 0.5,\n",
    "      'lr': 0.001,\n",
    "      'epochs': 30,\n",
    "  }\n",
    "args"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task type: subtoken prediction\n"
     ]
    }
   ],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = PygGraphPropPredDataset(name = \"ogbg-code2\") \n",
    "\n",
    "split_idx = dataset.get_idx_split() \n",
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False)\n",
    "print('Task type: {}'.format(dataset.task_type))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Expected input format of Evaluator for ogbg-code2\n",
      "{'seq_ref': seq_ref, 'seq_pred': seq_pred}\n",
      "- seq_ref: a list of lists of strings\n",
      "- seq_pred: a list of lists of strings\n",
      "where seq_ref stores the reference sequences of sub-tokens, and\n",
      "seq_pred stores the predicted sequences of sub-tokens.\n",
      "\n",
      "==== Expected output format of Evaluator for ogbg-code2\n",
      "{'F1': F1}\n",
      "- F1 (float): F1 score averaged over samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ogb.graphproppred import Evaluator\n",
    "\n",
    "evaluator = Evaluator(name = \"ogbg-code2\")\n",
    "print(evaluator.expected_input_format) \n",
    "print(evaluator.expected_output_format)\n",
    "# In most cases, input_dict is\n",
    "# input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "# result_dict = evaluator.eval(input_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout, return_embeds=True) :\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # a list of GCNConv layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        # a list of 1D batch normaliztion layers\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                self.convs.append(GCNConv(input_dim, hidden_dim))\n",
    "            elif i == num_layers - 1:\n",
    "                self.convs.append(GCNConv(hidden_dim, output_dim))\n",
    "            else: \n",
    "                self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "            if i < num_layers - 1:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_dim)) \n",
    "        # 1D softmax \n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "        # Skip classification layer and return node embeddings\n",
    "        self.return_embeds = return_embeds\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(len(self.convs)):\n",
    "            x =self.convs[i](x, edge_index)\n",
    "            if i < len(self.convs) - 1:\n",
    "                x = self.bns[i](x) \n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p = self.dropout, training=self.training)\n",
    "        if(self.return_embeds == True):\n",
    "            out = x\n",
    "        else:\n",
    "            out = self.softmax(x) \n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN_Graph Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_Graph(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(GCN_Graph, self).__init__()\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OGBLink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7113eff4bc1217f7b33968aaa90c3ff20c214f39e33d114be489ca5adb81751"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
